(this["webpackJsonpkdd-workshop"]=this["webpackJsonpkdd-workshop"]||[]).push([[0],{101:function(e,t,n){"use strict";n.r(t);var i=n(0),s=n.n(i),r=n(18),a=n.n(r),c=(n(88),n(89),n(90),n(23)),o=n(9),l=n(105),d=n(1),h={"/":"1","/organizers":"2","/timeline":"3","/submission":"4","/speakers":"5","/program":"6","/current":"7"};var j=function(){var e=Object(o.f)();return Object(d.jsxs)(l.a,{className:"navigator",mode:"horizontal",selectedKeys:h[e.pathname],children:[Object(d.jsxs)(l.a.Item,{children:["   ",Object(d.jsx)(c.b,{to:"/",children:"HOME"}),"                 "]},"1"),Object(d.jsxs)(l.a.Item,{children:["   ",Object(d.jsx)(c.b,{to:"/organizers",children:"ORGANIZERS"})," "]},"2"),Object(d.jsxs)(l.a.Item,{children:["   ",Object(d.jsx)(c.b,{to:"/timeline",children:"TIMELINE"}),"     "]},"3"),Object(d.jsxs)(l.a.Item,{children:["   ",Object(d.jsx)(c.b,{to:"/submission",children:"CALL FOR PAPERS"}),"     "]},"4"),Object(d.jsxs)(l.a.Item,{children:["   ",Object(d.jsx)(c.b,{to:"/speakers",children:"SPEAKERS"}),"     "]},"5"),Object(d.jsxs)(l.a.Item,{children:["   ",Object(d.jsx)(c.b,{to:"/program",children:"PROGRAM SKETCH"}),"     "]},"6")]})};var m=function(){return Object(d.jsx)("div",{children:Object(d.jsx)("div",{className:"container",children:Object(d.jsx)("div",{className:"row justify-content-center",children:Object(d.jsxs)("div",{className:"col-lg-8 cl-md-10",children:[Object(d.jsx)("h2",{children:"Introduction"}),Object(d.jsx)("p",{className:"contentText",children:"Recent years have witnessed the prosperity of deep learning in a variety of applications, such as computer vision, natural language processing and speech recognition and enhancement. And this success stimulates the proliferation of many benchmark deep neural models. Before practitioners develop models for the task of interest, they can actually have access to some off-the-shelf models, which are already trained on the same, similar or even totally different tasks. Those pretrained models are usually dedicated to mine the training data well, and the informative knowledge is supposed to exist in the learned representations or the model weights themselves. In this sense, how to mine the knowledge in the pretrained models is also of significance in achieving more promising performance."}),Object(d.jsx)("p",{className:"contentText",children:"There are multiple ways to fulfill the model mining. For example, inspired by the human education, we can leverage the pretrained models as privileged information or additional resources following the teacher-student paradigm. Then the knowledge can be manifested and distilled on the learned logits or intermediate features, such as attention maps, similarity among examples, and local graphs. As a result, the student models are expected to perform better with the help of the mined knowledge in teacher models. Likewise, pretrained models can also serve as a general yet powerful platform for adapting customized models for different target tasks. For example, large-scale pretrained models with huge parameters as BERT, GPT-3, and ViT show great generalization ability in many downstream tasks, and we can have decent performance for the target task with only limited data."}),Object(d.jsx)("div",{style:{height:20}}),Object(d.jsx)("h2",{children:"Topics of Interest"}),Object(d.jsx)("p",{className:"contentText",children:"The TOPIC model mining of this workshop aims to investigate more diverse and advanced manners in mining knowledge within models, which tends to leverage the pretrained models more wisely, elegantly and systematically. The topics of interest include the theory, algorithm and application of mining the values of models in different scenarios"}),Object(d.jsx)("div",{children:Object(d.jsxs)("ul",{className:"contentText",children:[Object(d.jsx)("li",{children:"Distilling a lightweight model from a well-trained heavy model, e.g., knowledge distillation or the teacher-student paradigm;"}),Object(d.jsx)("li",{children:"Continuously upgrading the model with new data, new concept or new tasks, e.g., continual learning, lifelong learning, zero-shot learning and multi-task learning."}),Object(d.jsx)("li",{children:"Boosting the performance of the model by carefully designing the predecessor tasks, e.g., pre-training, self-supervised and contrastive learning."}),Object(d.jsx)("li",{children:"Transferring the models across different datasets, domains or modalities, e.g., transfer learning and domain adaptation."})]})}),Object(d.jsx)("p",{className:"contentText",children:"Model mining as a special way of data mining is relevant to SIGKDD, and its audience including researchers and engineers will benefit a lot for designing more advanced algorithms for their tasks."})]})})})})};var b=function(){return Object(d.jsx)("div",{style:{paddingBottom:400},children:Object(d.jsx)("div",{className:"container",children:Object(d.jsx)("div",{className:"row justify-content-center",children:Object(d.jsxs)("div",{className:"col-lg-8 cl-md-10",children:[Object(d.jsx)("h2",{children:"Workshop Timeline"}),Object(d.jsx)("table",{className:"table",children:Object(d.jsxs)("tbody",{children:[Object(d.jsxs)("tr",{children:[Object(d.jsx)("td",{children:"Workshop Paper Submission"}),Object(d.jsxs)("td",{children:[Object(d.jsx)("div",{style:{textDecoration:"line-through",color:"red"},children:"May 20th, 2021"}),Object(d.jsx)("div",{children:"June 3rd, 2021"})]})]}),Object(d.jsxs)("tr",{children:[Object(d.jsx)("td",{children:"Workshop Paper Notification"}),Object(d.jsx)("td",{children:"June 20th, 2021"})]}),Object(d.jsxs)("tr",{children:[Object(d.jsx)("td",{children:"Workshop Program Final Submission and Full Website Online"}),Object(d.jsx)("td",{children:"July 2nd, 2021"})]}),Object(d.jsxs)("tr",{children:[Object(d.jsx)("td",{children:"Workshop Dates"}),Object(d.jsx)("td",{children:"August 14-18th, 2021"})]})]})})]})})})})};var p=function(){return Object(d.jsx)("div",{style:{paddingBottom:100},children:Object(d.jsx)("div",{className:"container",children:Object(d.jsx)("div",{className:"row justify-content-center",children:Object(d.jsxs)("div",{className:"col-lg-8 cl-md-10",children:[Object(d.jsx)("h2",{children:"Organizers"}),Object(d.jsx)("div",{children:Object(d.jsxs)("p",{className:"organizersText",children:[Object(d.jsxs)("a",{href:"https://shanyou92.github.io/",children:[" ",Object(d.jsx)("b",{children:"Shan You"})," "]})," is currently a Researcher at SenseTime, and also a post doc at Tsinghua University. Before that, he received a Bachelor of mathematics and applied mathematics (elite class) from Xi'an Jiaotong University, and a Ph.D. degree of computer science from Peking University. During pursing his PhD degree, he visited the UBTech Sydney AI Institute, the University of Sydney, and received awards from Qualcomm. His research interests include AutoML, reinforcement learning and other computer vision and machine learning topics, such as face recognition and object tracking. He has published his research outcomes in many top tier conferences and transactions."]})}),Object(d.jsx)("div",{children:Object(d.jsxs)("p",{className:"organizersText",children:[Object(d.jsxs)("a",{href:"http://changxu.xyz/",children:[" ",Object(d.jsx)("b",{children:" Chang Xu "})," "]}),"  is a Senior Lecturer and ARC DECRA Fellow at the School of Computer Science, University of Sydney. His recent interests focus on efficient deep learning and sparse networks, robust learning under noisy data or labels, and neural architecture search. He has published over 100 papers in prestigious journals and top tier conferences. He has received several paper awards, including Distinguished Paper Award in IJCAI 2018. He regularly severed as the senior PC or PC for many conferences, e.g., ICLR, SIGKDD, NIPS, ICML, CVPR, ICCV, IJCAI and AAAI. He has been recognized as Top Ten Distinguished Senior PC Member in IJCAI 2017."]})}),Object(d.jsx)("div",{children:Object(d.jsxs)("p",{className:"organizersText",children:[Object(d.jsxs)("a",{href:"http://wangfei.info/",children:[" ",Object(d.jsx)("b",{children:"Fei Wang"})," "]}),"  is the Associate Research Director of SenseTime. He leads a vibrant team to do fundamental research of computer vision and develop comprehensive solutions for the mobile intelligence industry. The goal of his team is to establish AI systems that make edge devices more intelligent and efficient. His research interests include Deep Learning, Edge Computation, etc. He has gained over 1000 Google Scholar Citations with recent publications during the last few years. Fei obtained his Bachelor\u2019s degree and Master's degree from Beijing University of Posts and Telecommunications."]})}),Object(d.jsx)("div",{children:Object(d.jsxs)("p",{className:"organizersText",children:[Object(d.jsxs)("a",{href:"http://bigeye.au.tsinghua.edu.cn/english/Introduction.html",children:[" ",Object(d.jsx)("b",{children:"Changshui Zhang"})," "]}),"  received the B.E. degree in mathematics from Peking University, Beijing, China, in 1986, and the M.S. and Ph.D. degrees in control science and engineering from Tsinghua University, Beijing, in 1989 and 1992, respectively. In 1992, he joined the Department of Automation, Tsinghua University, where he is currently a professor. His research interests include pattern recognition and machine learning. He is a Fellow member of the IEEE."]})})]})})})})};var g=function(){return Object(d.jsx)("div",{style:{paddingBottom:100},children:Object(d.jsx)("div",{className:"container",children:Object(d.jsx)("div",{className:"row justify-content-center",children:Object(d.jsxs)("div",{className:"col-lg-8 cl-md-10",children:[Object(d.jsx)("h2",{children:"Keynote Speakers"}),Object(d.jsx)("div",{className:"speakersText",children:Object(d.jsxs)("p",{children:[Object(d.jsx)("b",{children:" Title "}),":  K-priors: A General Principle of Adaptation ",Object(d.jsx)("br",{}),Object(d.jsx)("b",{children:" Abstract "}),":  Humans and animals have a natural ability to quickly adapt to their surroundings, but machine-learning models, when subjected to changes, often require a complete retraining from scratch. I will present Knowledge-adaptation priors (K-priors) to reduce the cost of retraining by enabling quick and accurate adaptation for a wide-variety of tasks and models. This is made possible by a combination of weight and function-space priors to reconstruct the gradients of the past, which recovers and generalizes many existing, but seemingly-unrelated, adaptation strategies. Overall, my hope is to convince the audience that K-priors provide an intuitive yet practical mechanism for generic adaptation in machine learning. ",Object(d.jsx)("br",{}),Object(d.jsx)("b",{children:" Speaker Profile "}),": ",Object(d.jsxs)("a",{href:"https://emtiyaz.github.io/",children:[" ",Object(d.jsx)("b",{children:"Emtiyaz Khan"})," "]})," (also known as Emti) is a team leader at the RIKEN center for Advanced Intelligence Project (AIP) in Tokyo where he leads the Approximate Bayesian Inference Team. He is also a visiting professor at the Tokyo University of Agriculture and Technology (TUAT). Previously, he was a postdoc and then a scientist at Ecole Polytechnique F\xe9d\xe9rale de Lausanne (EPFL), where he also taught two large machine learning courses and received a teaching award. He finished his PhD in machine learning from University of British Columbia in 2012. The main goal of Emti\u2019s research is to understand the principles of learning from data and use them to develop algorithms that can learn like living beings. For the past 10 years, his work has focused on developing Bayesian methods that could lead to such fundamental principles. The approximate Bayesian inference team now continues to use these principles, as well as derive new ones, to solve real-world problems."]})}),Object(d.jsx)("br",{}),Object(d.jsx)("div",{className:"speakersText",children:Object(d.jsxs)("p",{children:[Object(d.jsx)("b",{children:" Title "}),":  Towards Better Utilization of Pre-trained Models ",Object(d.jsx)("br",{}),Object(d.jsx)("b",{children:" Abstract "}),":  Pre-training, which first pretrains a large model on a large amount of unlabeled data and then fine-tunes the pre-trained model on downstream tasks, has become a domain paradigm in multiple AI fields, especially natural language  processing (NLP). In this talk, I will focus on better utilization of pre-trained models and ask two fundamental questions:",Object(d.jsxs)("ol",{style:{marginBottom:"0px"},children:[Object(d.jsx)("li",{children:" Is fine-tuning universally applicable to all downstream tasks? "}),Object(d.jsx)("li",{children:" How to efficiently utilize pretrained models considering diverse requirements of model size and latency in different downstream tasks? "})]}),"For the first question, I will show that direct fine-tuning does not work very well for an important NLP task: machine translation, and propose to fuse the pre-trained model with standard encoder-decoder framework, which can better leverage pre-trained models. ",Object(d.jsx)("br",{}),"For the second question, I will introduce our recent work, BERT-NAS, which leverages neural architecture search (NAS) to find lightweight models that achieve better accuracy than previous approaches and can be directly applied to different downstream tasks with adaptive model sizes for different requirements of memory or latency.",Object(d.jsx)("br",{}),Object(d.jsx)("b",{children:" Speaker Profile "}),": ",Object(d.jsxs)("a",{href:"https://www.microsoft.com/en-us/research/people/taoqin/",children:[" ",Object(d.jsx)("b",{children:"Dr. Tao Qin"})," "]})," is a Senior Principal Researcher and managing the Deep and Reinforcement Learning group at Microsoft Research Asia. His research interests include deep learning (with applications to machine translation, healthcare, speech synthesis and recognition, music understanding and composition), reinforcement learning (with applications to games and real-world problems), game theory and multi-agent systems (with applications to cloud computing, online and mobile advertising), and information retrieval and computational advertising. His team helped Microsoft achieve human parity in Chinese-English machine translation in 2018, won the first place for 8 translation tasks in WMT 2019, and built the world-best Mahjong AI, named Suphx, which achieved 10 DAN on the Tenhou platform in 2019."]})})]})})})})};var u=function(){return Object(d.jsx)("div",{children:Object(d.jsx)("div",{className:"container",children:Object(d.jsx)("div",{className:"row justify-content-center",children:Object(d.jsxs)("div",{className:"col-lg-8 cl-md-10",children:[Object(d.jsx)("h2",{children:"CALL FOR PAPERS"}),Object(d.jsxs)("p",{children:["Submissions should follow the "," ",Object(d.jsx)("a",{href:"https://kdd.org/kdd2021/calls/view/call-for-research-track-papers",children:Object(d.jsx)("b",{children:"SIGKDD formatting requirements"})}),"   "," ","and will be evaluated using the "," ",Object(d.jsx)("a",{href:"https://kdd.org/kdd2021/calls/view/call-for-research-track-papers",children:Object(d.jsx)("b",{children:"SIGKDD Research Track evaluation criteria"})}),". "," ","Preference will be given to papers that are reproducible, and authors are encouraged to share their data and code publicly whenever possible. Submissions are strongly recommended to be ",Object(d.jsx)("b",{children:" no more than 4 pages "}),", excluding references or supplementary materials (all in a single pdf). The appropriateness of using additional pages over the recommended length will be judged by reviewers. Papers must be submitted in PDF format to easychair",Object(d.jsxs)("a",{href:"https://easychair.org/conferences/?conf=wmm2021",children:[" ",Object(d.jsx)("b",{children:" https://easychair.org/conferences/?conf=wmm2021 "})," "]}),"   "," ","and formatted according to the new",Object(d.jsxs)("a",{href:"https://www.acm.org/publications/proceedings-template",children:[" ",Object(d.jsx)("b",{children:" Standard ACM Conference Proceedings Template "})," "]})," ."]}),Object(d.jsx)("p",{children:"The review process is single-round and double-blind (submission files have to be anonymized). The program committee will select the papers based on originality, presentation, and technical quality for spotlight and/or poster presentation. Concurrent submissions to other journals and conferences are acceptable."}),Object(d.jsxs)("p",{children:["All questions about submissions should be emailed to  ",Object(d.jsxs)("a",{href:"mailto: youshan@sensetime.com",children:["  ",Object(d.jsx)("b",{children:" youshan@sensetime.com "})," "]})]})]})})})})};var f=function(){return Object(d.jsx)("div",{style:{paddingBottom:50},children:Object(d.jsx)("div",{className:"container",children:Object(d.jsx)("div",{className:"row justify-content-center",children:Object(d.jsxs)("div",{className:"col-lg-8 cl-md-10",children:[Object(d.jsx)("h2",{children:"Workshop Schedule"}),Object(d.jsx)("table",{className:"table",children:Object(d.jsxs)("tbody",{children:[Object(d.jsxs)("tr",{children:[Object(d.jsx)("td",{children:" Opening Remark "}),Object(d.jsx)("td",{className:"tableCenter",children:" 08:00-08:10 "})]}),Object(d.jsxs)("tr",{children:[Object(d.jsxs)("td",{children:[" Spotlight 1: Vision Transformer Pruning  ",Object(d.jsx)("a",{href:"https://drive.google.com/file/d/1UZ4hk66trje5BGnqOXWOgcb-HGRi77Ma/view?usp=sharing",children:"(Paper Link)"})," "]}),Object(d.jsx)("td",{className:"tableCenter",children:"08:10-08:20"})]}),Object(d.jsxs)("tr",{children:[Object(d.jsxs)("td",{children:[" Spotlight 2: Defense of Adversarial Examples through Removal of Effective Adversarial Pathways ",Object(d.jsx)("a",{href:"https://drive.google.com/file/d/1ZFr3gYP0aVZF-yC3V-e61DG9keqVaGNZ/view?usp=sharing",children:"(Paper Link)"})," "]}),Object(d.jsx)("td",{className:"tableCenter",children:"08:20-08:30"})]}),Object(d.jsxs)("tr",{children:[Object(d.jsxs)("td",{children:[" Spotlight 3:  CNN-based Local Vision Transformer for COVID-19 Diagnosis ",Object(d.jsx)("a",{href:"https://drive.google.com/file/d/1VZW_7AJ8KfD0UxswUKsW10sDUcXASZa0/view?usp=sharing",children:"(Paper Link)"})," "]}),Object(d.jsx)("td",{className:"tableCenter",children:"08:30-08:40"})]}),Object(d.jsxs)("tr",{children:[Object(d.jsxs)("td",{children:[" Spotlight 4:  Learning with Imperfect Distilled Knowledge ",Object(d.jsx)("a",{href:"",children:"(Paper Link)"})," "]}),Object(d.jsx)("td",{className:"tableCenter",children:"08:40-08:50"})]}),Object(d.jsxs)("tr",{children:[Object(d.jsx)("td",{children:" Break "}),Object(d.jsx)("td",{className:"tableCenter",children:"08:50-09:00"})]}),Object(d.jsxs)("tr",{children:[Object(d.jsxs)("td",{children:[" Keynote - ",Object(d.jsx)("a",{href:"https://www.microsoft.com/en-us/research/people/taoqin/",children:" Tao Qin "})," (Microsoft Research Asia) "]}),Object(d.jsx)("td",{className:"tableCenter",children:"09:00-09:40"})]}),Object(d.jsxs)("tr",{children:[Object(d.jsxs)("td",{children:[" Keynote - ",Object(d.jsx)("a",{href:"https://emtiyaz.github.io/",children:" Emtiyaz Khan "})," (RIKEN)  "]}),Object(d.jsx)("td",{className:"tableCenter",children:"09:40-10:20"})]}),Object(d.jsxs)("tr",{children:[Object(d.jsx)("td",{children:" Break "}),Object(d.jsx)("td",{className:"tableCenter",children:"10:20-10:30"})]}),Object(d.jsxs)("tr",{children:[Object(d.jsxs)("td",{children:[" Spotlight 5: FraudNE: a Joint Embedding Approach for Fraud Detection ",Object(d.jsx)("a",{href:"https://drive.google.com/file/d/1tw6jRYPPqEfIlFy8nlbVNCDG_OAD4T1L/view?usp=sharing",children:"(Paper Link)"})," "]}),Object(d.jsx)("td",{className:"tableCenter",children:"10:30-10:40"})]}),Object(d.jsxs)("tr",{children:[Object(d.jsxs)("td",{children:[" Spotlight 6: Structured DropConnect for Uncertainty Inference in Image Classification ",Object(d.jsx)("a",{href:"https://drive.google.com/file/d/1N0zUeTCoezZczZGzGRouyCn77FcMfUi4/view?usp=sharing",children:"(Paper Link)"}),"  "]}),Object(d.jsx)("td",{className:"tableCenter",children:"10:40-10:50"})]}),Object(d.jsxs)("tr",{children:[Object(d.jsxs)("td",{children:[" Spotlight 7:  Cross-layer Navigation Convolutional Neural Network for Fine-grained Visual Classification ",Object(d.jsx)("a",{href:"https://drive.google.com/file/d/1x6_hk6XJADhQBCQtz3ny_68x3Kn3UXT_/view?usp=sharing",children:"(Paper Link)"})," "]}),Object(d.jsx)("td",{className:"tableCenter",children:"10:50-11:00"})]}),Object(d.jsxs)("tr",{children:[Object(d.jsxs)("td",{children:[" Spotlight 8:  Deformable Generative Networks for Few-shot Cross-Language Font Generation ",Object(d.jsx)("a",{href:"https://drive.google.com/file/d/1T2lKJ89X2XO5abVFb_oE_QZPbaltsmx1/view?usp=sharing",children:"(Paper Link)"})," "]}),Object(d.jsx)("td",{className:"tableCenter",children:"11:00-11:10"})]}),Object(d.jsxs)("tr",{children:[Object(d.jsxs)("td",{children:[" Poster Session - GatherTown ",Object(d.jsx)("a",{href:"https://gather.town/invite?token=CsaFMUXH",children:"(Invite Link)"})," "]}),Object(d.jsx)("td",{className:"tableCenter",children:"11:10-12:00"})]})]})})]})})})})};var x=n(103),O=x.a.Content;var v=function(){return Object(d.jsx)(c.a,{children:Object(d.jsxs)(x.a,{className:"layout",children:[Object(d.jsx)(j,{}),Object(d.jsxs)(O,{children:[Object(d.jsx)("div",{className:"imageOverlay",children:Object(d.jsxs)("h1",{style:{textAlign:"center",color:"white",position:"relative"},children:["KDD Workshop 2021 ",Object(d.jsx)("br",{}),"Model Mining"]})}),Object(d.jsx)("div",{style:{padding:"0 50px",marginTop:30,marginBottom:20,minHeight:500},children:Object(d.jsxs)(o.c,{children:[Object(d.jsx)(o.a,{path:"/organizers",component:p}),Object(d.jsx)(o.a,{path:"/timeline",component:b}),Object(d.jsx)(o.a,{path:"/speakers",component:g}),Object(d.jsx)(o.a,{path:"/submission",component:u}),Object(d.jsx)(o.a,{path:"/program",component:f}),Object(d.jsx)(o.a,{path:"/",component:m})]})})]})]})})},w=function(e){e&&e instanceof Function&&n.e(3).then(n.bind(null,106)).then((function(t){var n=t.getCLS,i=t.getFID,s=t.getFCP,r=t.getLCP,a=t.getTTFB;n(e),i(e),s(e),r(e),a(e)}))};a.a.render(Object(d.jsx)(s.a.StrictMode,{children:Object(d.jsx)(v,{})}),document.getElementById("root")),w()},88:function(e,t,n){},90:function(e,t,n){}},[[101,1,2]]]);
//# sourceMappingURL=main.5c181565.chunk.js.map